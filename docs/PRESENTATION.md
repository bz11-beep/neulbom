# 늘봄 프로젝트 발표 자료

## 문서 정보

| 항목 | 내용 |
|------|------|
| 프로젝트명 | 늘봄 (AI 기반 노인 돌봄 음성 분석 시스템) |
| 문서 버전 | 1.0 |
| 작성일 | 2026-02-09 |
| 개발 기간 | 2025년 12월 ~ 2026년 2월 (2025.12.05 ~ 2026.02.10) |
| 개발 인원 | 5명 (최선임 총괄기획, 지태민 프론트엔드, 김승민 백엔드, 최대영 DB/IoT, 조민솔 기획/문서) |

---

## 목차

1. [프로젝트 배경](#1-프로젝트-배경)
2. [프로젝트 목적 및 목표](#2-프로젝트-목적-및-목표)
3. [시스템 아키텍처](#3-시스템-아키텍처)
4. [기술 스택 요약](#4-기술-스택-요약)
5. [AI 파이프라인](#5-ai-파이프라인)
6. [8차원 음성 분석 체계](#6-8차원-음성-분석-체계)
7. [주요 기능 소개](#7-주요-기능-소개)
8. [데이터베이스 설계](#8-데이터베이스-설계)
9. [시연 시나리오 요약](#9-시연-시나리오-요약)
10. [프로젝트 성과](#10-프로젝트-성과)
11. [향후 계획](#11-향후-계획)

---

## 1. 프로젝트 배경

### 고령화 사회의 현실

- **초고령사회 진입**: 대한민국은 2025년 65세 이상 인구 비율 20%를 돌파하며 초고령사회에 진입
- **독거 어르신 증가**: 전국 독거 어르신 약 200만 명 이상, 해마다 증가 추세
- **고독사 위험**: 독거 어르신의 사회적 고립 및 고독사 사례 증가
- **돌봄 인력 부족**: 방문 돌봄 서비스의 인력 한계, 24시간 케어 불가

### 기존 돌봄 서비스의 한계

| 기존 방식 | 한계점 |
|----------|--------|
| 주간 방문 서비스 | 주 1-2회로 실시간 상태 파악 불가 |
| 전화 안부 확인 | 음성의 감정/상태를 객관적으로 분석 불가 |
| CCTV/IoT 센서 | 물리적 활동만 감지, 정서적 상태 파악 불가 |
| 돌봄 로봇 | 고비용, 자연스러운 대화 어려움 |

### AI 돌봄의 필요성

- 24시간 비대면 음성 분석으로 **실시간 정서 모니터링** 가능
- AI 대화 에이전트를 통한 **외로움 해소 및 인지 자극**
- 음성 데이터의 **정량적 분석**으로 인지 저하 조기 감지
- 보호자에게 **객관적 데이터 기반 리포트** 제공

---

## 2. 프로젝트 목적 및 목표

### 프로젝트 목적

> 독거 어르신의 음성을 AI로 분석하여 감정 상태를 파악하고,
> AI 손녀 '보미'와의 자연스러운 대화를 통해 정서적 케어를 제공하며,
> 보호자에게 실시간 알림과 분석 리포트를 전달하는 통합 돌봄 시스템

### 핵심 목표

| 목표 | 설명 |
|------|------|
| 실시간 감정 분석 | 음성으로부터 감정을 실시간 분석하여 이상 징후 조기 감지 |
| AI 대화 에이전트 | 어르신이 편안하게 대화할 수 있는 AI 손녀 '보미' 구현 |
| 8차원 음성 점수 | 음성의 다양한 특성을 정량화하여 객관적 상태 지표 제공 |
| 보호자 알림 | 위험 감지 시 보호자에게 즉시 알림 전송 |
| 데이터 축적 | 장기 데이터 축적을 통한 인지 변화 트렌드 분석 기반 마련 |

---

## 3. 시스템 아키텍처

```
┌─────────────────────────────────────────────────────────────────────────┐
│                          늘봄 시스템 아키텍처                             │
└─────────────────────────────────────────────────────────────────────────┘

  ┌──────────────────────┐     ┌──────────────────────────────────────┐
  │    Frontend (Client)  │     │         Backend (Server)             │
  │                      │     │                                      │
  │  ┌────────────────┐  │     │  ┌─────────────────────────────────┐ │
  │  │   index.html   │  │     │  │     Flask (Port 5000)           │ │
  │  │   (SPA 구조)    │  │     │  │                                 │ │
  │  │                │  │ SSE │  │  - 라우팅, 템플릿 렌더링          │ │
  │  │  - login       │<─┼─────┼─>│  - 회원가입/로그인 API           │ │
  │  │  - signup      │  │     │  │  - 음성 분석 API (/api/analyze)  │ │
  │  │  - dashboard   │  │     │  │  - 활동량 조회 API              │ │
  │  │  - bomi chat   │  │     │  │  - 기기/알림 관리 API           │ │
  │  │  - report      │  │     │  │                                 │ │
  │  │  - health      │  │     │  └─────────┬───────────────────────┘ │
  │  │  - mypage      │  │     │            │                         │
  │  └────────────────┘  │     │            v                         │
  │                      │     │  ┌─────────────────────────────────┐ │
  │  ┌────────────────┐  │     │  │      AI 파이프라인               │ │
  │  │   script.js    │  │     │  │                                 │ │
  │  │                │  │     │  │  1. SpeechAnalyzer              │ │
  │  │  - Chart.js    │  │     │  │     - faster-whisper (STT)      │ │
  │  │  - MediaRecorder│  │     │  │     - EmotionEnsemble          │ │
  │  │  - SSE Client  │  │     │  │       (KcELECTRA + Wav2Vec2)   │ │
  │  │  - Fetch API   │  │     │  │                                 │ │
  │  └────────────────┘  │     │  │  2. LLMHandler                 │ │
  │                      │     │  │     - Q&A Dataset (200+)        │ │
  │  ┌────────────────┐  │     │  │     - GPT-4o-mini (폴백)        │ │
  │  │   style.css    │  │     │  │                                 │ │
  │  │  Material Icons│  │     │  │  3. EdgeTTSHandler              │ │
  │  └────────────────┘  │     │  │     - Edge TTS (SunHiNeural)    │ │
  └──────────────────────┘     │  └─────────┬───────────────────────┘ │
                               │            │                         │
                               │            v                         │
  ┌──────────────────────┐     │  ┌─────────────────────────────────┐ │
  │    IoT 센서 연동      │     │  │      MySQL (care_db)            │ │
  │                      │     │  │                                 │ │
  │  - 모션 센서         │─────┼─>│  - tb_guardian  (보호자)         │ │
  │  - 환경 센서         │     │  │  - tb_senior   (어르신)         │ │
  │                      │     │  │  - tb_device   (기기)           │ │
  └──────────────────────┘     │  │  - tb_sensor   (센서)           │ │
                               │  │  - tb_sensing  (센싱 데이터)     │ │
  ┌──────────────────────┐     │  │  - tb_voice_log (음성 로그)     │ │
  │    Grafana 모니터링   │     │  │  - tb_analysis (분석 결과)      │ │
  │                      │─────┼─>│  - tb_alert    (알림)           │ │
  │  - 임계값 알림       │     │  │                                 │ │
  │  - 대시보드          │     │  └─────────────────────────────────┘ │
  └──────────────────────┘     └──────────────────────────────────────┘
```

### FastAPI 분석 서버 (대안 구성)

```
  ┌──────────────────────────────┐
  │   FastAPI (Port 8000)        │
  │                              │
  │  - /analyze (음성 분석 API)   │
  │  - /health (상태 확인)        │
  │  - /latest-sensing           │
  │                              │
  │  SpeechAnalyzer + LLM 통합   │
  └──────────────────────────────┘
```

> Flask 서버가 메인 서비스를 담당하며, FastAPI 서버는 독립적인 분석 전용 API로도 활용 가능합니다.

---

## 4. 기술 스택 요약

### Backend

| 분류 | 기술 | 버전/상세 |
|------|------|----------|
| 웹 프레임워크 | Flask | 메인 서비스 (Port 5000) |
| API 서버 | FastAPI + Uvicorn | 분석 전용 서버 (Port 8000) |
| 데이터베이스 | MySQL | care_db (8 테이블) |
| DB 드라이버 | PyMySQL | MySQL 연결 |
| 인증 | 세션 기반 | Flask Session + Cookie |

### AI / 딥러닝

| 분류 | 기술 | 용도 |
|------|------|------|
| STT | faster-whisper (tiny, int8) | 한국어 음성을 텍스트로 변환 |
| 텍스트 감정 분석 | KcELECTRA (MelissaJ/koelectra-emotion-6) | 한국어 텍스트 6감정 분류 |
| 음성 감정 분석 | Wav2Vec2 (jungjongho/wav2vec2-xlsr-korean) | 한국어 음성 감정 인식 |
| 피치 분석 | librosa YIN 알고리즘 | Z-score 기반 음성 역동성 측정 |
| LLM | GPT-4o-mini (OpenAI API) | AI 대화 응답 생성 |
| Q&A 매칭 | 자체 시맨틱 매칭 엔진 | 200+ Q&A 데이터셋 3단계 매칭 |
| TTS | Edge TTS (SunHiNeural) | 한국어 음성 합성 |
| 토크나이저 | KcELECTRA-base-v2022 | 어휘 다양성(TTR) 분석 |

### Frontend

| 분류 | 기술 | 용도 |
|------|------|------|
| 템플릿 | Jinja2 | Flask 서버 사이드 렌더링 |
| 차트 | Chart.js + datalabels | 감정/활동량 시각화 |
| 아이콘 | Material Icons Round | UI 아이콘 |
| 폰트 | Noto Sans KR | 한국어 웹 폰트 |
| 음성 녹음 | MediaRecorder API | 브라우저 마이크 녹음 |
| 실시간 통신 | SSE (Server-Sent Events) | 분석 진행 상황 스트리밍 |
| 주소 검색 | 다음 우편번호 API | 회원가입 주소 입력 |

### 인프라

| 분류 | 기술 | 용도 |
|------|------|------|
| 모니터링 | Grafana | 임계값 알림, 센서 데이터 시각화 |
| GPU 가속 | CUDA (선택) | PyTorch 모델 추론 가속 |
| SSL | PyOpenSSL | 자체 서명 인증서 (HTTPS) |

---

## 5. AI 파이프라인

### 전체 흐름도

```
┌──────────┐    ┌──────────┐    ┌───────────────┐    ┌──────────┐    ┌──────────┐
│  음성    │    │   STT    │    │   감정 분석    │    │   LLM    │    │   TTS    │
│  입력    │──> │ (Whisper)│──> │ (Ensemble)    │──> │ (GPT-4o) │──> │ (Edge)   │
│          │    │          │    │               │    │          │    │          │
│ .wav/.webm│    │ text     │    │ emotion+score │    │ response │    │ .mp3     │
└──────────┘    └──────────┘    └───────────────┘    └──────────┘    └──────────┘
     |               |                 |                  |               |
     v               v                 v                  v               v
  브라우저       텍스트 변환       감정 라벨 +        AI 응답 텍스트    음성 합성
  MediaRecorder  (한국어)        8차원 점수          (보미 페르소나)   (한국어 여성)
```

### 1단계: STT (Speech-to-Text)

```
입력: .wav/.webm 오디오 파일
  |
  v
faster-whisper (tiny 모델, int8 양자화)
  - 언어: 한국어 고정
  - beam_size: 1 (속도 우선)
  - VAD 필터: 활성화 (무음 구간 자동 제거)
  |
  v
출력: 텍스트, 단어 수, WPM, 발화 길이, 침묵 시간
```

- **모델**: `openai/whisper-tiny` (int8 양자화로 속도 극대화)
- **최적화**: 파일을 Whisper가 직접 읽도록 하여 전처리 오버헤드 제거
- **VAD 필터**: 무음 구간을 자동 제거하여 정확도 향상

### 2단계: 감정 분석 (Emotion Ensemble)

```
           텍스트              오디오 (16kHz, 3초)
             |                        |
             v                        v
     ┌───────────────┐      ┌─────────────────┐
     │  KcELECTRA    │      │   Wav2Vec2      │
     │  (텍스트 감정) │      │  (음성 감정)     │
     │               │      │                 │
     │  6감정 분류    │      │  5감정 분류      │
     │  (기쁨,슬픔,  │      │  (angry,happy,  │
     │   분노,불안,  │      │   sad,neutral,  │
     │   당황,중립)  │      │   fear)         │
     └───────┬───────┘      └────────┬────────┘
             |                       |
             v                       v
         text_label              audio_label
         text_conf               audio_conf
                                     |
                                     v
                           ┌─────────────────┐
                           │  Pitch Z-score  │
                           │  (librosa YIN)  │
                           │                 │
                           │  z_peak 계산     │
                           └────────┬────────┘
                                    |
                                    v
                         ┌────────────────────┐
                         │   멀티모달 융합     │
                         │                    │
                         │ if z_peak > 2.5    │
                         │   && audio 확실:   │
                         │   audio_label 채택  │
                         │ else:              │
                         │   text_label 채택   │
                         └────────┬───────────┘
                                  |
                                  v
                           final_emotion
```

- **텍스트 모델**: `MelissaJ/koelectra-emotion-6-emotion-base` (한국어 6감정)
- **음성 모델**: `jungjongho/wav2vec2-xlsr-korean-speech-emotion-recognition`
- **융합 규칙**: 기본적으로 텍스트 감정을 따르되, 음성의 피치 변화가 클 때(Z-peak > 2.5) 음성 감정을 반영

### 3단계: LLM (Large Language Model)

```
┌─────────────────────────────────────────────────┐
│                 LLM 응답 생성 로직                │
├─────────────────────────────────────────────────┤
│                                                 │
│  1. Q&A 데이터셋 검색 (200+ 항목)                │
│     - 1단계: 정확한 일치                          │
│     - 2단계: 부분 일치 (포함 관계)                │
│     - 3단계: 키워드 일치 (단어 기반)              │
│     |                                           │
│     +--> 매칭 성공: 미리 정의된 응답 + 감정 반환   │
│     |                                           │
│     +--> 매칭 실패: GPT-4o-mini API 호출         │
│                                                 │
│  2. GPT-4o-mini 호출                            │
│     - 기본 페르소나: 20대 손녀 '보미'             │
│     - 감정 상태에 따른 동적 프롬프트              │
│     - 점수 기반 위험 감지 프롬프트                │
│     - 대화 히스토리 유지 (최대 10턴)              │
│                                                 │
└─────────────────────────────────────────────────┘
```

- **Q&A 데이터셋**: 10개 카테고리 (인사, 약, 음식, 건강, 감정, 날씨, 가족, 활동, 안전, 시간)
- **보미 페르소나**: 20대 손녀 캐릭터, 친근한 존댓말, 1-2문장 짧은 응답
- **감정 반영**: 슬픔일 때 위로, 분노일 때 경청, 불안일 때 안심, 기쁨일 때 맞장구
- **위험 감지**: 평균 점수 50점 미만 또는 감정 점수 40점 미만 시 고위험 프롬프트 추가

### 4단계: TTS (Text-to-Speech)

```
AI 응답 텍스트
  |
  v
Edge TTS (Microsoft)
  - 음성: ko-KR-SunHiNeural (밝고 친절한 여성)
  - 속도: +0% (기본)
  - 출력: MP3 파일
  |
  v
브라우저에서 재생 (<audio> 태그)
```

- **8+ 한국어 음성** 지원 (여성 5종, 남성 4종)
- 기본 음성: `SunHiNeural` (밝고 친절한 톤)
- 비동기 음성 생성 (asyncio)

---

## 6. 8차원 음성 분석 체계

### 분석 지표 상세

| 차원 | 지표명 | 측정값 | 최적 범위 | 의미 |
|------|--------|--------|----------|------|
| 1 | 말의 속도 | WPM (분당 단어 수) | 100~150 | 인지 처리 속도 반영 |
| 2 | 발화 길이 | 초 (seconds) | 3.0~10.0 | 표현력 및 참여도 |
| 3 | 반응 속도 | 초 (seconds) | 0.0~2.0 | 인지 반응 능력 |
| 4 | 단어 수 | 개 (count) | 5~20 | 언어 산출 능력 |
| 5 | 어휘 다양성 | TTR (Type-Token Ratio) | 0.6~0.9 | 인지 기능 지표 |
| 6 | 침묵 패턴 | 초 (seconds) | 0.0~1.0 | 비정상적 침묵 감지 |
| 7 | 감정 안정도 | 점수 (0~100) | 70~100 | 정서적 안정 상태 |
| 8 | 활력도 | VPR (Vocalization-to-Pause Ratio) | 2.0~10.0 | 우울/무기력 감지 |

### 점수 계산 방식

```
점수 계산 로직:

  값이 최적 범위 내:  100점
  값이 최적 범위 미만: (값 / 최소값) * 100
  값이 최적 범위 초과: 100 - ((초과량 / 최대값) * 100)

  감정 점수 별도 계산:
    긍정 감정(기쁨):     80 + (확신도 x 20)  -->  80~100점
    중립 감정:           70 + (확신도 x 10)  -->  70~80점
    부정 감정(슬픔 등):  60 - (확신도 x 60)  -->   0~60점

  종합 점수 = 8개 차원의 평균
```

### 위험도 판정

| 종합 점수 | 감정 점수 | 판정 | 조치 |
|----------|----------|------|------|
| 80점 이상 | 70점 이상 | 정상 | - |
| 65~80점 | 60~70점 | 관심 필요 | 따뜻한 대화 유도 |
| 50~65점 | 40~60점 | 주의 | 보호자에게 알림 |
| 50점 미만 | 40점 미만 | 고위험 | 즉시 보호자 알림 + 세심한 대화 |

---

## 7. 주요 기능 소개

### 7.1 대시보드 (Dashboard)

| 기능 | 설명 |
|------|------|
| 환영 인사 | 보호자명, 어르신명 표시 + 날짜 |
| 감정 분석 차트 | 최근 감정 분석 결과를 도넛/바 차트로 시각화 |
| 활동량 현황 | IoT 모션 센서 연동, 일간/주간/월간 활동량 그래프 |
| 인지 상태 | 어르신의 최근 인지 상태 요약 |

- **Chart.js** 기반 인터랙티브 차트
- 활동량은 `tb_sensing` 테이블의 모션 센서 데이터와 연동
- 일간: 오늘 감지 횟수, 주간: 최근 7일 일별, 월간: 최근 4주 주별

### 7.2 보미 대화 (Bomi Chat)

| 기능 | 설명 |
|------|------|
| 음성 녹음 | MediaRecorder API로 브라우저 마이크 녹음 |
| 실시간 진행 | SSE 스트리밍으로 분석 단계별 진행 상황 표시 |
| 감정 분석 | 실시간 감정 라벨 + 확신도 표시 |
| AI 응답 | 보미 캐릭터 텍스트 응답 + TTS 음성 재생 |
| 분석 패널 | 감정 상태, 음성 톤, 말하기 속도, 종합 점수 표시 |

- 녹음 전 `/api/create-voice-session`으로 센싱 세션 생성
- `/api/check-sensor`로 센서 등록 여부 확인 (미등록 시 녹음 비활성화)
- 분석 결과는 `tb_voice_log` + `tb_analysis`에 자동 저장

### 7.3 리포트 (Report)

| 기능 | 설명 |
|------|------|
| 분석 이력 | 최근 음성 분석 결과 목록 (날짜, 감정, 점수) |
| 감정 트렌드 | 시간에 따른 감정 변화 추이 그래프 |
| 8차원 점수 | 각 차원별 점수 상세 표시 |
| 보호자 리포트 | GPT-4o-mini 기반 자연어 상태 요약 생성 |

### 7.4 알림 (Alert)

| 기능 | 설명 |
|------|------|
| 실시간 알림 | Grafana 연동 임계값 초과 시 자동 알림 생성 |
| 알림 벨 | 네비게이션 바 알림 뱃지 (안 읽은 알림 수 표시) |
| 알림 목록 | 최근 10건 알림 조회 (유형, 내용, 시간) |
| 읽음 처리 | 개별/전체 읽음 처리 |

- `tb_alert` 테이블에서 `received_yes = 0`인 알림을 실시간 폴링
- 알림 유형: 감정 이상, 활동량 저하, 센서 이상 등

---

## 8. 데이터베이스 설계

### ERD 간략도

```
┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│ tb_guardian   │     │  tb_senior   │     │  tb_device   │
│──────────────│     │──────────────│     │──────────────│
│ guardian_id PK│──┐  │ senior_id PK │  ┌──│ device_id PK │
│ user_id      │  └─>│ guardian_id FK│  │  │ device_uid   │
│ password     │     │ name         │<─┘  │ device_name  │
│ name         │     │ birthdate    │     │ location     │
│ phone        │     │ gender       │     │ senior_id FK │
│ post_num     │     │ phone        │     │ installed_at │
│ addr1        │     │ post_num     │     └──────┬───────┘
│ addr2        │     │ addr1        │            │
│ relation     │     │ addr2        │            v
│ voice_approved│     │ living_type  │     ┌──────────────┐
│ created_at   │     │ created_at   │     │  tb_sensor   │
└──────────────┘     └──────────────┘     │──────────────│
                                          │ sensor_id PK │
                                          │ device_id FK │
                                          │ sensor_type  │
                                          │ created_at   │
                                          └──────┬───────┘
                                                 │
                            ┌────────────────────┼────────────────────┐
                            v                    v                    v
                     ┌──────────────┐     ┌──────────────┐    ┌──────────────┐
                     │ tb_sensing   │     │ tb_voice_log │    │  tb_alert    │
                     │──────────────│     │──────────────│    │──────────────│
                     │ sensing_id PK│     │ voice_id  PK │    │ alert_id  PK │
                     │ sensor_id FK │     │ senior_id FK │    │ alert_type   │
                     │ sensing_type │     │ sensing_id FK│    │ alert_content│
                     │ sensing_value│     │ voice_text   │    │ sented_at    │
                     │ created_at   │     │ response_time│    │ received_yes │
                     └──────────────┘     │ utterance_len│    └──────────────┘
                                          │ created_at   │
                                          └──────┬───────┘
                                                 │
                                                 v
                                          ┌──────────────┐
                                          │ tb_analysis  │
                                          │──────────────│
                                          │ analysis_id PK│
                                          │ voice_idx FK │
                                          │ emotion_label│
                                          │ stt_text     │
                                          │ behavior_policy│
                                          │ hap_ratio    │
                                          │ sad_ratio    │
                                          │ neu_ratio    │
                                          │ ang_ratio    │
                                          │ anxi_ratio   │
                                          │ emba_ratio   │
                                          │ heart_ratio  │
                                          └──────────────┘
```

### 테이블 요약

| 테이블 | 역할 | 주요 컬럼 |
|--------|------|----------|
| `tb_guardian` | 보호자 정보 | user_id, password, name, phone, addr |
| `tb_senior` | 어르신 정보 | name, birthdate, gender, living_type, guardian_id |
| `tb_device` | IoT 기기 | device_uid, device_name, location, senior_id |
| `tb_sensor` | 센서 | sensor_type (motion/env), device_id |
| `tb_sensing` | 센싱 데이터 | sensing_type, sensing_value, sensor_id |
| `tb_voice_log` | 음성 로그 | voice_text, response_time_sec, utterance_length |
| `tb_analysis` | 감정 분석 결과 | emotion_label, 7가지 감정 비율 (hap~heart) |
| `tb_alert` | 알림 | alert_type, alert_content, received_yes |

### 주요 관계

- `tb_guardian` 1:N `tb_senior` (한 보호자가 여러 어르신 관리 가능)
- `tb_senior` 1:N `tb_device` (한 어르신에게 여러 기기 설치)
- `tb_device` 1:N `tb_sensor` (한 기기에 여러 센서)
- `tb_sensor` 1:N `tb_sensing` (한 센서에서 여러 센싱 데이터)
- `tb_voice_log` 1:1 `tb_analysis` (음성 로그당 하나의 분석 결과)

---

## 9. 시연 시나리오 요약

```
[1] 메인 화면     서비스 소개 및 첫 인상                    (1분)
      |
[2] 회원가입     보호자 + 어르신 등록, 주소 API 연동        (2분)
      |
[3] 대시보드     감정 차트, 활동량, 인지 상태 확인           (2분)
      |
[4] 보미 대화    음성 녹음 > STT > 감정분석 > AI응답 > TTS  (5분)
      |           (핵심 시연: AI 파이프라인 실시간 동작)
[5] 리포트       분석 이력, 8차원 점수, 감정 트렌드          (2분)
      |
[6] 헬스체크     시스템 구성 요소 상태 확인                  (1분)
      |
[7] 마이페이지   정보 수정, 기기 관리                       (1분)
      |
[8] 알림 확인    Grafana 연동 알림, 읽음 처리               (1분)

                                               총 소요: 약 15분
```

---

## 10. 프로젝트 성과

### 기술적 성과

| 성과 항목 | 내용 |
|----------|------|
| AI 파이프라인 구축 | STT > 감정 분석 > LLM > TTS 4단계 파이프라인 완성 |
| 멀티모달 앙상블 | KcELECTRA(텍스트) + Wav2Vec2(음성) + Pitch Z-score 3중 융합 |
| 실시간 스트리밍 | SSE 기반 분석 진행 상황 실시간 전송 구현 |
| 8차원 음성 점수 | 학술 논문 기반(Mundt et al., 2007) VPR 지표 포함 |
| Q&A 데이터셋 | 10개 카테고리 200+ 항목 시맨틱 매칭 엔진 자체 구현 |
| IoT 연동 | 모션/환경 센서 데이터 연동 활동량 모니터링 |
| 알림 시스템 | Grafana 연동 임계값 기반 자동 알림 |

### 서비스 측면 성과

| 성과 항목 | 내용 |
|----------|------|
| 보미 캐릭터 | 자연스러운 AI 손녀 대화 에이전트 구현 |
| 보호자 지원 | 대시보드, 리포트, 알림을 통한 원격 돌봄 지원 |
| 감정 기반 케어 | 감정 상태에 따른 동적 대화 전략 적용 |
| 데이터 축적 | 장기 음성 데이터 축적 기반 마련 |

---

## 11. 향후 계획

### 단기 계획 (1~3개월)

| 계획 | 내용 |
|------|------|
| 모델 고도화 | STT 모델 업그레이드 (tiny > small/medium), 감정 분석 정확도 향상 |
| Q&A 확장 | 데이터셋 500+ 항목으로 확대, 카테고리 세분화 |
| 보호자 앱 | 모바일 앱 (React Native) 개발로 알림 푸시 지원 |
| 보안 강화 | 비밀번호 암호화 (bcrypt), JWT 토큰 인증 전환 |

### 중기 계획 (3~6개월)

| 계획 | 내용 |
|------|------|
| 인지 저하 탐지 | 장기 음성 데이터 기반 인지 기능 변화 감지 알고리즘 개발 |
| 전용 디바이스 | 어르신 전용 음성 대화 기기 (스마트 스피커형) 개발 |
| 다국어 지원 | 영어, 중국어 등 다국어 확장 |
| 클라우드 배포 | AWS/GCP 클라우드 배포 및 확장성 확보 |

### 장기 비전

| 비전 | 내용 |
|------|------|
| AI 건강 예측 | 음성 패턴 변화로 건강 이상 사전 예측 |
| 지자체 연동 | 공공 돌봄 서비스 연계 (독거 어르신 안전 관리) |
| 의료 연계 | 병원/의료기관 데이터 연동으로 원격 건강 관리 |
| 표준화 | 음성 기반 노인 건강 평가 표준 지표 제안 |

---

## 부록: 팀 역할 및 기여도

| 영역 | 담당 내용 |
|------|----------|
| AI/백엔드 | 음성 분석 파이프라인, 감정 앙상블 모델, LLM 연동, Q&A 데이터셋 |
| 프론트엔드 | SPA 구조 UI/UX, Chart.js 시각화, MediaRecorder 녹음, SSE 클라이언트 |
| 데이터베이스 | MySQL 스키마 설계, 8테이블 구축, 데이터 CRUD |
| IoT/인프라 | 센서 연동, Grafana 알림, 서버 배포 |

---

> **늘봄** - 항상 봄처럼 따뜻한 돌봄이 함께하는 시스템
