# 늘봄 성능 테스트 보고서

## 문서 정보

| 항목 | 내용 |
|------|------|
| 프로젝트명 | 늘봄 (AI 기반 노인 돌봄 음성 분석 시스템) |
| 문서 버전 | 1.0 |
| 작성일 | 2026-02-09 |
| 개발 기간 | 2025년 12월 ~ 2026년 2월 (2025.12.05 ~ 2026.02.10) |
| 개발 인원 | 5명 (최선임 총괄기획, 지태민 프론트엔드, 김승민 백엔드, 최대영 DB/IoT, 조민솔 기획/문서) |

---

## 목차

1. [테스트 개요](#1-테스트-개요)
2. [테스트 환경](#2-테스트-환경)
3. [비기능 요구사항 결과 요약](#3-비기능-요구사항-결과-요약)
4. [상세 테스트 결과](#4-상세-테스트-결과)
   - 4.1 STT 처리 속도
   - 4.2 감정 분석 속도
   - 4.3 LLM 응답 속도
   - 4.4 TTS 생성 속도
   - 4.5 전체 파이프라인 (End-to-End)
   - 4.6 API 응답 속도
   - 4.7 동시 사용자 처리
   - 4.8 페이지 로딩 속도
5. [결론 및 개선 사항](#5-결론-및-개선-사항)

---

## 1. 테스트 개요

### 1.1 테스트 목적

본 테스트는 늘봄 시스템의 비기능 요구사항(NF-001 ~ NF-004)에 대한 충족 여부를 검증하고, 전체 음성 분석 파이프라인(STT, 감정 분석, LLM, TTS)의 처리 성능을 정량적으로 측정하기 위해 수행되었다.

### 1.2 테스트 일시

| 항목 | 내용 |
|------|------|
| 테스트 기간 | 2026-02-05 ~ 2026-02-08 |
| 최종 테스트 | 2026-02-08 |
| 반복 횟수 | 각 항목 5회 반복 후 평균 산출 |

### 1.3 테스트 도구

| 도구 | 용도 | 비고 |
|------|------|------|
| Python `time` 모듈 | 각 단계별 처리 시간 측정 | 서버 내장 타이머 |
| `test_client.py` | API 요청 자동화 및 성능 측정 | 프로젝트 포함 테스트 스크립트 |
| Chrome DevTools | 프론트엔드 페이지 로딩 속도 측정 | Network/Performance 탭 |
| `concurrent.futures` | 동시 사용자 처리 시뮬레이션 | Python 내장 병렬 처리 |
| `requests` / `httpx` | HTTP API 호출 및 응답 시간 측정 | REST 엔드포인트 테스트 |

---

## 2. 테스트 환경

### 2.1 서버 구성

| 서비스 | 포트 | 프레임워크 | 역할 |
|--------|------|-----------|------|
| Flask Web Server | 5000 (HTTPS) | Flask + Jinja2 | 메인 웹 서버, API 라우팅, 음성 분석 파이프라인 |
| FastAPI Server | 8000 | FastAPI + Uvicorn | 대안 비동기 음성 분석 서버 |
| MySQL Database | 3306 | MySQL (care_db) | 사용자, 디바이스, 음성 로그, 분석 결과 저장 |

### 2.2 하드웨어 사양

| 항목 | 사양 |
|------|------|
| OS | Windows |
| CPU | Intel Core (멀티코어) |
| RAM | 16GB |
| GPU | CPU 모드 (CUDA 미사용) |
| 스토리지 | SSD |
| Python | 3.x |

### 2.3 AI 모델 구성

| 모델 | 용도 | 사양 |
|------|------|------|
| faster-whisper (tiny) | STT 음성 인식 | int8 양자화, beam_size=1, VAD 필터 활성 |
| KcELECTRA (koelectra-emotion-6-emotion-base) | 텍스트 감정 분석 | 최대 128 토큰, softmax 출력 |
| Wav2Vec2-XLSR | 오디오 감정 분석 | 16kHz 리샘플링, 최대 3초 |
| GPT-4o-mini | LLM 대화 생성 | OpenAI API, max_completion_tokens=1500 |
| Edge TTS (ko-KR-SunHiNeural) | 음성 합성 | Microsoft Edge TTS, MP3 출력 |

---

## 3. 비기능 요구사항 결과 요약

| 요구사항 ID | 항목 | 목표값 | 측정값 (평균) | 판정 |
|------------|------|--------|--------------|------|
| NF-001 | STT 처리 시간 | < 오디오 길이의 1x | 오디오 길이의 0.3x ~ 0.5x | **PASS** |
| NF-002 | 감정 분석 응답 | < 3초 | 1.2초 ~ 1.8초 | **PASS** |
| NF-003 | TTS 생성 시간 | < 5초 | 1.0초 ~ 2.8초 | **PASS** |
| NF-004 | API 응답 시간 | < 2초 | 0.05초 ~ 0.35초 | **PASS** |

> 모든 비기능 요구사항이 목표값을 충족하였다.

---

## 4. 상세 테스트 결과

### 4.1 STT 처리 속도

**테스트 대상**: faster-whisper (tiny 모델, int8 양자화, beam_size=1, VAD 필터)

**테스트 방법**: 다양한 길이의 한국어 음성 파일을 `SpeechAnalyzer._whisper_analysis_fast()`에 입력하여 처리 시간을 측정한다.

| 오디오 길이 | 처리 시간 (평균) | RTF (Real-Time Factor) | 목표 (< 1.0x) | 판정 |
|------------|-----------------|----------------------|---------------|------|
| 5초 | 1.6초 | 0.32x | < 1.0x | PASS |
| 10초 | 3.5초 | 0.35x | < 1.0x | PASS |
| 30초 | 12.8초 | 0.43x | < 1.0x | PASS |
| 60초 | 28.2초 | 0.47x | < 1.0x | PASS |

**분석**:
- faster-whisper tiny 모델은 int8 양자화와 beam_size=1 설정으로 CPU 환경에서도 실시간 대비 약 0.3x ~ 0.5x의 처리 속도를 달성하였다.
- VAD(Voice Activity Detection) 필터가 활성화되어 무음 구간을 건너뛰므로 실질적인 처리 시간이 추가로 단축된다.
- 오디오 길이가 길어질수록 RTF가 소폭 증가하지만, 60초 음성에서도 0.47x로 목표값(1.0x)을 크게 하회한다.

---

### 4.2 감정 분석 속도

**테스트 대상**: KcELECTRA 텍스트 감정 분석 + Wav2Vec2 오디오 감정 분석 + YIN 피치 분석 (앙상블)

**테스트 방법**: STT 변환 완료 후 텍스트와 오디오를 `EmotionEnsemble.predict()`에 입력하여 전체 앙상블 소요 시간을 측정한다.

| 분석 단계 | 처리 시간 (평균) | 비고 |
|-----------|-----------------|------|
| KcELECTRA 텍스트 감정 분석 | 0.25초 | 최대 128 토큰, GPU 미사용 |
| Wav2Vec2 오디오 감정 분석 | 0.65초 | 16kHz, 최대 3초 오디오 |
| YIN 피치 분석 (librosa.yin) | 0.18초 | 65~500Hz 범위, Z-peak 계산 |
| 앙상블 결합 + 감정 점수 산출 | 0.05초 | 가중치 결합, 감정 매핑 |
| **총 감정 분석 시간** | **1.13초** | - |

| 오디오 길이별 | 5초 음성 | 10초 음성 | 30초 음성 | 목표 |
|-------------|---------|----------|----------|------|
| 감정 분석 시간 | 1.13초 | 1.35초 | 1.82초 | < 3초 |
| 판정 | PASS | PASS | PASS | - |

**분석**:
- KcELECTRA 텍스트 감정 분석은 토큰화된 텍스트 입력만 처리하므로 0.25초 이내로 매우 빠르다.
- Wav2Vec2 오디오 감정 분석은 오디오를 최대 3초로 제한하여 입력하므로 오디오 길이에 관계없이 일정한 처리 시간을 유지한다.
- 피치 분석(YIN 알고리즘)은 librosa를 통해 수행되며, Z-peak 연산까지 포함하여 0.2초 내외로 처리된다.
- 전체 앙상블 분석이 3초 목표를 1초 이상의 여유로 충족한다.

---

### 4.3 LLM 응답 속도

**테스트 대상**: Q&A 데이터셋 매칭 (로컬) + GPT-4o-mini API 호출 (원격)

**테스트 방법**: 다양한 유형의 어르신 발화 텍스트에 대해 LLM 응답 생성 시간을 측정한다. Q&A 매칭은 로컬 처리, 매칭 실패 시 GPT-4o-mini API를 호출한다.

| 응답 경로 | 처리 시간 (평균) | 비고 |
|-----------|-----------------|------|
| Q&A 데이터셋 매칭 성공 (정확 일치) | 0.02초 | 10개 카테고리, 44개 항목 로컬 검색 |
| Q&A 데이터셋 매칭 성공 (부분/키워드 일치) | 0.05초 | 3단계 매칭 로직 순차 수행 |
| GPT-4o-mini API 호출 (매칭 실패) | 1.5초 ~ 2.8초 | 네트워크 지연 포함, max_tokens=1500 |

| 발화 유형 | 예시 | 응답 경로 | 처리 시간 |
|-----------|------|----------|----------|
| 인사 | "안녕하세요" | Q&A 매칭 | 0.02초 |
| 약 복용 | "약 먹었어" | Q&A 매칭 | 0.03초 |
| 식사 문의 | "밥 먹었니?" | Q&A 매칭 | 0.02초 |
| 자유 대화 | "요즘 무릎이 아파" | GPT-4o-mini | 1.8초 |
| 감정 표현 | "외로워서 힘들어" | GPT-4o-mini | 2.2초 |
| 응급 상황 | "어지러워 넘어졌어" | GPT-4o-mini (고위험) | 2.5초 |

**분석**:
- Q&A 데이터셋 매칭 시 응답 시간이 거의 무시할 수 있는 수준(< 0.1초)으로, 자주 사용되는 대화 패턴에 대해 즉각적인 응답이 가능하다.
- GPT-4o-mini API 호출 시 평균 1.5초 ~ 2.8초가 소요되며, 이는 네트워크 상태에 따라 변동이 있다.
- 고위험 프롬프트(감정 점수 < 40 또는 평균 점수 < 50)가 적용되는 경우, 추가적인 컨텍스트가 포함되어 소폭 시간이 증가한다.
- Q&A 매칭 우선 전략으로 인해 전체 LLM 호출 빈도가 약 40% 감소하여 API 비용 절감 효과도 확인되었다.

---

### 4.4 TTS 생성 속도

**테스트 대상**: Microsoft Edge TTS (ko-KR-SunHiNeural, rate=+0%)

**테스트 방법**: 다양한 길이의 한국어 응답 텍스트에 대해 Edge TTS MP3 생성 시간을 측정한다.

| 텍스트 길이 | 텍스트 예시 | 생성 시간 (평균) | 출력 파일 크기 | 판정 |
|------------|-----------|-----------------|--------------|------|
| 짧은 문장 (10자 내외) | "네, 할머니!" | 0.8초 | 12KB | PASS |
| 보통 문장 (30자 내외) | "할머니, 오늘 날씨가 좋으니까 산책 한 번 나가 보세요!" | 1.2초 | 35KB | PASS |
| 긴 문장 (50자 내외) | "할머니, 무릎이 아프시면 따뜻한 찜질을 하시고 푹 쉬세요. 내일은 좀 나아지실 거예요!" | 1.8초 | 55KB | PASS |
| 매우 긴 문장 (100자 내외) | 2문장 이상 복합 응답 | 2.8초 | 98KB | PASS |

**분석**:
- Edge TTS는 Microsoft 클라우드 서비스를 통해 고품질 한국어 신경망 음성을 생성하며, 네트워크 기반이므로 안정적인 인터넷 환경이 전제된다.
- 보미 캐릭터의 응답은 대화 규칙에 따라 1~2문장(30~50자)으로 제한되므로, 실제 운영 환경에서의 TTS 생성 시간은 대부분 1.0초 ~ 2.0초 범위이다.
- 5초 목표값 대비 충분한 여유가 있으며, 비동기 생성(asyncio)을 적용하여 다른 처리와 병렬로 실행 가능하다.

---

### 4.5 전체 파이프라인 (End-to-End)

**테스트 대상**: 음성 녹음 파일 업로드 ~ TTS 응답 음성 생성 완료까지의 전체 처리 시간 (`/api/analyze` SSE 스트림)

**파이프라인 단계별 소요 시간 (10초 음성 기준)**:

| 단계 | SSE Step | 처리 내용 | 소요 시간 (평균) |
|------|----------|----------|-----------------|
| 1 | step 1 | 파일 업로드 및 임시 저장 | 0.15초 |
| 2 | step 2~3 | STT 음성 인식 (faster-whisper) | 3.5초 |
| 3 | step 4 | 감정 분석 (KcELECTRA + Wav2Vec2 + Pitch) | 1.35초 |
| 4 | step 5 | AI 응답 생성 (Q&A 매칭 또는 GPT-4o-mini) | 0.05초 ~ 2.5초 |
| 5 | step 5.5~5.7 | TTS 음성 합성 (Edge TTS) | 1.2초 |
| 6 | step 6 | DB 저장 (tb_voice_log + tb_analysis) | 0.08초 |
| 7 | step 7 | 임시 파일 정리 | 0.02초 |
| | | **전체 합계 (Q&A 매칭 성공 시)** | **6.35초** |
| | | **전체 합계 (GPT-4o-mini 호출 시)** | **8.80초** |

| 오디오 길이 | Q&A 매칭 경로 | GPT-4o-mini 경로 |
|------------|-------------|-----------------|
| 5초 | 4.4초 | 6.9초 |
| 10초 | 6.4초 | 8.8초 |
| 30초 | 16.0초 | 18.4초 |
| 60초 | 30.5초 | 33.0초 |

**분석**:
- 전체 파이프라인에서 STT 처리가 가장 많은 비중(약 40~50%)을 차지한다.
- Q&A 데이터셋 매칭 성공 시 GPT-4o-mini API 호출을 생략하여 약 2~3초의 시간 절감 효과가 있다.
- SSE 스트리밍 방식으로 각 단계의 진행 상태를 실시간으로 사용자에게 전달하므로, 체감 대기 시간이 실제 처리 시간보다 짧게 느껴진다.
- 일상적인 어르신 발화(5~15초)의 경우 전체 파이프라인이 약 5~10초 이내에 완료된다.

---

### 4.6 API 응답 속도

**테스트 대상**: 일반 REST API 엔드포인트 (음성 분석 제외)

**테스트 방법**: 각 API에 정상적인 요청을 5회 반복 전송하여 평균 응답 시간을 측정한다.

| API 엔드포인트 | 메서드 | 평균 응답 시간 | 목표 (< 2초) | 판정 |
|---------------|--------|--------------|-------------|------|
| `POST /api/signup` | POST | 0.12초 | < 2초 | PASS |
| `POST /api/login` | POST | 0.08초 | < 2초 | PASS |
| `POST /api/check-duplicate` | POST | 0.05초 | < 2초 | PASS |
| `POST /api/change-password` | POST | 0.07초 | < 2초 | PASS |
| `POST /api/activity-daily` | POST | 0.10초 | < 2초 | PASS |
| `POST /api/activity-weekly` | POST | 0.18초 | < 2초 | PASS |
| `POST /api/activity-monthly` | POST | 0.22초 | < 2초 | PASS |
| `GET /api/check-alert` | GET | 0.06초 | < 2초 | PASS |
| `POST /api/alert-list` | POST | 0.08초 | < 2초 | PASS |
| `POST /api/alert-read-all` | POST | 0.05초 | < 2초 | PASS |
| `POST /api/add-device` | POST | 0.15초 | < 2초 | PASS |
| `POST /api/check-sensor` | POST | 0.09초 | < 2초 | PASS |
| `POST /api/create-voice-session` | POST | 0.11초 | < 2초 | PASS |
| `POST /api/update-guardian` | POST | 0.07초 | < 2초 | PASS |
| `POST /api/update-senior` | POST | 0.08초 | < 2초 | PASS |
| `GET /api/tts-audio/<file>` | GET | 0.03초 | < 2초 | PASS |
| `POST /api/simulate-data` | POST | 0.10초 | < 2초 | PASS |

**분석**:
- 모든 일반 API의 응답 시간이 0.35초 이내로, 2초 목표값을 크게 하회한다.
- `activity-weekly` 및 `activity-monthly` API는 7일/4주간 날짜별 루프 쿼리를 수행하여 상대적으로 시간이 소요되지만, 여전히 0.25초 미만이다.
- DB 조회(SELECT)와 갱신(INSERT/UPDATE) 모두 PyMySQL 직접 연결 방식으로 빠르게 처리된다.
- TTS 오디오 파일 제공(`/api/tts-audio/<file>`)은 Flask `send_from_directory`를 사용하여 정적 파일 수준의 응답 속도를 보인다.

---

### 4.7 동시 사용자 처리

**테스트 대상**: 음성 분석 SSE 스트림 동시 요청 처리 (`/api/analyze`)

**테스트 방법**: `concurrent.futures.ThreadPoolExecutor`를 사용하여 동시에 여러 건의 음성 분석 요청을 전송하고, 각 요청의 완료 시간 및 성공률을 측정한다.

| 동시 요청 수 | 평균 응답 시간 (10초 음성) | 최대 응답 시간 | 성공률 | 비고 |
|-------------|--------------------------|--------------|--------|------|
| 1명 | 6.4초 | 7.1초 | 100% | 기본 성능 |
| 2명 | 8.2초 | 9.5초 | 100% | 소폭 지연 |
| 3명 | 11.5초 | 13.8초 | 100% | AI 모델 자원 경합 |
| 5명 | 18.2초 | 22.5초 | 100% | 현저한 지연 |
| 10명 | 35.8초 | 42.0초 | 90% | 타임아웃 발생 시작 |

**분석**:
- 현재 시스템은 단일 서버에서 AI 모델(Whisper, KcELECTRA, Wav2Vec2)을 공유하므로, 동시 요청 시 CPU 자원 경합으로 처리 시간이 선형적으로 증가한다.
- 3명 이하의 동시 사용자에서는 허용 가능한 수준의 지연이 발생한다.
- 5명 이상의 동시 요청에서는 체감 지연이 크게 증가하며, 10명 동시 요청에서는 일부 타임아웃이 발생하였다.
- 늘봄 시스템의 실제 운영 환경에서는 어르신별 음성 대화가 시간차를 두고 발생하므로, 동시 5명 이상의 요청은 드문 경우로 판단된다.
- GPU 환경 도입 또는 모델 인스턴스 분리 시 동시 처리 성능이 크게 개선될 수 있다.

---

### 4.8 페이지 로딩 속도

**테스트 대상**: 주요 HTML 페이지 초기 로딩 시간

**테스트 방법**: Chrome DevTools Network 탭에서 각 페이지의 DOMContentLoaded 및 Load 이벤트 시간을 측정한다. 캐시를 비운 상태에서 5회 반복 측정하였다.

| 페이지 | 경로 | DOMContentLoaded (평균) | Load (평균) | 주요 리소스 |
|--------|------|------------------------|------------|-----------|
| 로그인 | `/templates/login.html` | 0.35초 | 0.52초 | CSS, JS |
| 회원가입 | `/templates/signup.html` | 0.40초 | 0.65초 | CSS, JS, Daum Postcode API |
| 대시보드 | `/templates/dashboard.html` | 0.55초 | 1.20초 | CSS, JS, Chart.js, Material Icons, API 데이터 |
| 보미 (음성 대화) | `/templates/bomi.html` | 0.45초 | 0.85초 | CSS, JS, 보미 캐릭터 이미지 9종 |
| 리포트 | `/templates/report.html` | 0.50초 | 1.10초 | CSS, JS, Chart.js, API 데이터 |
| 건강 관리 | `/templates/health.html` | 0.38초 | 0.60초 | CSS, JS |
| 마이페이지 | `/templates/mypage.html` | 0.35초 | 0.55초 | CSS, JS |

**분석**:
- 모든 페이지의 DOMContentLoaded가 0.6초 이내로, 사용자가 화면을 인식하는 시점이 매우 빠르다.
- 대시보드와 리포트 페이지는 Chart.js 라이브러리 로딩 및 초기 API 데이터 호출로 인해 Load 시간이 1초를 초과하지만, 데이터 로딩 중 스켈레톤 UI가 표시되므로 체감 지연이 크지 않다.
- 보미 페이지는 보미 캐릭터 이미지(9종)를 사전 로딩하여 대화 중 표정 전환이 즉각적으로 이루어진다.
- 외부 CDN 리소스(Material Icons, Daum Postcode API)의 로딩 시간은 네트워크 상태에 따라 변동이 있다.

---

## 5. 결론 및 개선 사항

### 5.1 결론

| 항목 | 판정 | 상세 |
|------|------|------|
| NF-001: STT 처리 시간 | **PASS** | 오디오 길이의 0.3x ~ 0.5x로 목표(1.0x) 대비 2~3배 빠름 |
| NF-002: 감정 분석 응답 | **PASS** | 1.1초 ~ 1.8초로 목표(3초) 대비 충분한 여유 |
| NF-003: TTS 생성 시간 | **PASS** | 1.0초 ~ 2.8초로 목표(5초) 대비 안정적 |
| NF-004: API 응답 시간 | **PASS** | 전체 API 0.35초 이내로 목표(2초) 대비 우수 |

늘봄 시스템은 설정된 4가지 비기능 요구사항을 모두 충족하며, 특히 faster-whisper tiny 모델의 int8 양자화 및 Q&A 데이터셋 매칭 우선 전략이 전체 파이프라인의 응답 속도를 크게 향상시키는 핵심 최적화 요소로 확인되었다.

### 5.2 성능 최적화 적용 사항

본 테스트에서 확인된 주요 최적화 사항은 다음과 같다.

| 최적화 항목 | 적용 내용 | 효과 |
|------------|----------|------|
| Whisper 모델 경량화 | tiny 모델 + int8 양자화 | 처리 속도 3~5배 향상 (base 대비) |
| Beam Size 최소화 | beam_size=1 | STT 속도 약 2배 향상 |
| VAD 필터 적용 | vad_filter=True | 무음 구간 건너뛰기로 STT 시간 단축 |
| Q&A 매칭 우선 전략 | 로컬 Q&A 매칭 -> LLM 호출 | API 호출 약 40% 감소, 응답 시간 2~3초 절감 |
| Wav2Vec2 입력 제한 | 오디오 최대 3초로 제한 | 감정 분석 시간 일정하게 유지 |
| Edge TTS 비동기 | asyncio 기반 비동기 생성 | 블로킹 최소화 |

### 5.3 향후 개선 사항

| 우선순위 | 개선 항목 | 기대 효과 |
|---------|----------|----------|
| 높음 | GPU(CUDA) 환경 도입 | STT 및 감정 분석 속도 5~10배 향상, 동시 처리 성능 개선 |
| 높음 | 모델 인스턴스 풀링 | 동시 사용자 처리 시 자원 경합 해소 |
| 중간 | Whisper small 모델 업그레이드 (GPU 전제) | STT 정확도 향상 (속도 유지 가능) |
| 중간 | Q&A 데이터셋 확장 | LLM API 호출 빈도 추가 감소, 응답 시간 단축 |
| 중간 | activity API 쿼리 최적화 | 날짜별 루프 대신 GROUP BY 단일 쿼리로 변경 |
| 낮음 | CDN 리소스 로컬 캐싱 | 페이지 로딩 속도 안정화 (네트워크 의존도 감소) |
| 낮음 | TTS 결과 캐싱 | 동일 응답에 대한 반복 TTS 생성 방지 |

---

## 문서 이력

| 버전 | 날짜 | 작성자 | 변경 내용 |
|------|------|--------|----------|
| 1.0 | 2026-02-09 | - | 최초 작성. 8개 테스트 항목에 대한 성능 측정 결과 및 분석 |
